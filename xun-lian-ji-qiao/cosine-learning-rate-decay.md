# Cosine Learning Rate Decay

在 warmup 之后的训练过程中, 学习率不断衰减是一个提高精度的好方法. 其中有 setp decay 和 cosine decay 等, 前者是随着 epoch 增大学习率不断减去一个小的数, 后者是让学习率随着训练过程曲线下降
